{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxiriyoFc95zwbCF2orMh3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vonewman/Audio-course-hf/blob/main/Reconnaissance_automatique_de_la_parole_avec_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reconnaissance automatique de la parole avec pipeline"
      ],
      "metadata": {
        "id": "YCO6nWWCCLB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c4pfRqUVB8Pv"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La reconnaissance automatique de la parole (ASR pour Automatic Speech Recognition) est une tâche qui implique la transcription de l’enregistrement vocal en texte. Cette tâche a de nombreuses applications pratiques, de la création de sous-titres codés pour les vidéos à l’activation des commandes vocales pour les assistants virtuels comme Siri et Alexa.\n",
        "\n",
        "Dans cette section, nous utiliserons le pipeline automatic-speech-recognition pour transcrire un enregistrement audio d’une personne posant une question sur le paiement d’une facture en utilisant le même jeu de données MINDS-14 qu’auparavant."
      ],
      "metadata": {
        "id": "RL2OrRxKCwFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "asr = pipeline(\"automatic-speech-recognition\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX-YBx_TCOiJ",
        "outputId": "75e6b19d-d056-45e2-bd06-dc59ba410759"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuite, nous allons prendre un exemple du jeu de données et transmettre ses données brutes au pipeline :"
      ],
      "metadata": {
        "id": "hQL_YaELC-hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"en-AU\", split=\"train\")\n",
        "minds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB6Bc98sDwME",
        "outputId": "1f575a80-afc0-4bde-c55f-ed8a1d640c3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
              "    num_rows: 654\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]\n",
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtMQtp0JC4h8",
        "outputId": "f4fc277f-8194-4de7-c8b5-cf552c8fc614"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"AT'LL ROUT THE PONOTTE FLFLOOR ALL THE MATTER THE LITTLE\"}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"english_transcription\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-Gw4MImtDAq0",
        "outputId": "5f75e1cd-c0ec-4b0f-d77a-e02ffa1120e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I would like to pay my electricity bill using my card can you please assist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import Audio\n",
        "\n",
        "minds = load_dataset(\"PolyAI/minds14\", name=\"de-DE\", split=\"train\")\n",
        "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))"
      ],
      "metadata": {
        "id": "BV8u3VM3FRJd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = minds[0]\n",
        "example[\"transcription\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zk-lNhOLFogw",
        "outputId": "3b359775-4717-437f-d517-c56c935378f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ich möchte gerne Geld auf mein Konto einzahlen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "asr = pipeline(\"automatic-speech-recognition\", model=\"bofenghuang/asr-wav2vec2-ctc-french\")\n",
        "asr(example[\"audio\"][\"array\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLmAqHpCFrib",
        "outputId": "fe2db3e3-fb9c-4482-9d37-a818d126eb51"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Could not load the `decoder` for bofenghuang/asr-wav2vec2-ctc-french. Defaulting to raw CTC. Error: No module named 'kenlm'\n",
            "Try to install `kenlm`: `pip install kenlm\n",
            "Try to install `pyctcdecode`: `pip install pyctcdecode\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'shmartecka  ekelt of min countor ensoin'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PY5yQQdtF8wq"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}